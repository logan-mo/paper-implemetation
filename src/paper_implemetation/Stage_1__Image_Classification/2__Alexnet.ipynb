{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotes from the paper:\\n\\nThe Alexnet paper used Convolutional Neural Networks to win the ImageNet competition in 2012.\\n\\nGoal:\\nImage Classification\\n\\nDataset Used:\\nImagenet-1000\\nImagenet is a 15 million labelled high-resolution (Relatively speeaking, compared to NIST which was 28 x28, this is 256 x 256) images in 22,000 categories. \\nThe 1000 category subset was used for this paper.\\n\\nMethod Used:\\nConvolution layers, occasionally followed by max-pooling layers. The final layers are fully connected layers, with Dropout layers in between.\\nEnds with a 1000-way softmax layer.\\n\\nConvolution dimension calculation:\\nhttps://madebyollin.github.io/convnet-calculator/\\n\\nArchitecture:\\nInput (3 x 256, 256)\\n- Convolutional Layer 1 \\n    GPU1 - (96 filters, 11 x 11, stride 4, padding 0) -> (output dim: (96, 62, 62))\\n    GPU2 - (96 filters, 11 x 11, stride 4, padding 0) -> (output dim: (96, 62, 62))\\n- Max Pooling Layer 1\\n    GPU1 - (3 x 3, stride 2) -> (output dim: (96, 31, 31))\\n    GPU2 - (3 x 3, stride 2) -> (output dim: (96, 31, 31))\\n- Convolutional Layer 2\\n    GPU1 - (256 filters, 5 x 5, stride 1, padding 2) -> (output dim: (256, 31, 31))\\n    GPU2 - (256 filters, 5 x 5, stride 1, padding 2) -> (output dim: (256, 31, 31))\\n- Max Pooling Layer 2\\n    GPU1 - (3 x 3, stride 2) -> (output dim: (256, 15, 15))\\n    GPU2 - (3 x 3, stride 2) -> (output dim: (256, 15, 15))\\n- Convolutional Layer 3\\n    GPU1 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\\n    GPU2 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\\n- Convolutional Layer 4\\n    GPU1 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\\n    GPU2 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\\n- Convolutional Layer 5\\n    GPU1 - (256 filters, 3 x 3, stride 1, padding 1) -> (output dim: (256, 15, 15))\\n    GPU2 - (256 filters, 3 x 3, stride 1, padding 1) -> (output dim: (256, 15, 15))\\n- Max Pooling Layer 3\\n    GPU1 - (3 x 3, stride 2) -> (output dim: (256, 7, 7))\\n    GPU2 - (3 x 3, stride 2) -> (output dim: (256, 7, 7))\\n- Fully Connected Layer 1\\n    GPU1 - (4096 neurons) -> (output dim: (4096))\\n    GPU2 - (4096 neurons) -> (output dim: (4096))\\n- Fully Connected Layer 2\\n    GPU1 - (4096 neurons) -> (output dim: (4096))\\n    GPU2 - (4096 neurons) -> (output dim: (4096))\\n- Fully Connected Layer 3\\n    1000 Neurons -> (output dim: (1000))\\n- Softmax Layer\\n    1000 Neurons -> (output dim: (1000))\\n    \\nInstead of using 2 GPUs, we will make the network branching.\\n\\nKeep in mind this:\\n\\nTraining Parameters / Hyperparamters:\\n- Data Augmentation: Randomly cropped 224x224 patches from the 256x256 images, and horizontally mirroring them.\\n    - This means that on test time, the image is resized to 256x256, and then 5 224x224 patches are cropped from it, and mirrored, and the network is run on all of them. The final prediction is the average of the 10 predictions.\\n- They wrote a Cuda ConvNet from scratch to train the network. BASED\\n- SGD with momentum 0.9 and weight decay 0.0005\\n- Batch Size: 128\\n\\nMetrics Defined:\\nError Rate\\n- Number of misclassified test samples / Total number of test samples\\n\\nTop 1 vs top 5 error rate\\n- Top 1 error rate is the number of test samples for which the correct label is not among the top 1 predicted labels\\n- Top 5 error rate is the number of test samples for which the correct label is not among the top 5 predicted labels\\n\\nResults:\\n- Top-1 error rate: 37.5%\\n- Top-5 error rate: 17.0%\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notes from the paper:\n",
    "\n",
    "The Alexnet paper used Convolutional Neural Networks to win the ImageNet competition in 2012.\n",
    "\n",
    "Goal:\n",
    "Image Classification\n",
    "\n",
    "Dataset Used:\n",
    "Imagenet-1000\n",
    "Imagenet is a 15 million labelled high-resolution (Relatively speeaking, compared to NIST which was 28 x28, this is 256 x 256) images in 22,000 categories. \n",
    "The 1000 category subset was used for this paper.\n",
    "\n",
    "Method Used:\n",
    "Convolution layers, occasionally followed by max-pooling layers. The final layers are fully connected layers, with Dropout layers in between.\n",
    "Ends with a 1000-way softmax layer.\n",
    "\n",
    "Convolution dimension calculation:\n",
    "https://madebyollin.github.io/convnet-calculator/\n",
    "\n",
    "Architecture:\n",
    "Input (3 x 256, 256)\n",
    "- Convolutional Layer 1 \n",
    "    GPU1 - (96 filters, 11 x 11, stride 4, padding 0) -> (output dim: (96, 62, 62))\n",
    "    GPU2 - (96 filters, 11 x 11, stride 4, padding 0) -> (output dim: (96, 62, 62))\n",
    "- Max Pooling Layer 1\n",
    "    GPU1 - (3 x 3, stride 2) -> (output dim: (96, 31, 31))\n",
    "    GPU2 - (3 x 3, stride 2) -> (output dim: (96, 31, 31))\n",
    "- Convolutional Layer 2\n",
    "    GPU1 - (256 filters, 5 x 5, stride 1, padding 2) -> (output dim: (256, 31, 31))\n",
    "    GPU2 - (256 filters, 5 x 5, stride 1, padding 2) -> (output dim: (256, 31, 31))\n",
    "- Max Pooling Layer 2\n",
    "    GPU1 - (3 x 3, stride 2) -> (output dim: (256, 15, 15))\n",
    "    GPU2 - (3 x 3, stride 2) -> (output dim: (256, 15, 15))\n",
    "- Convolutional Layer 3\n",
    "    GPU1 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\n",
    "    GPU2 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\n",
    "- Convolutional Layer 4\n",
    "    GPU1 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\n",
    "    GPU2 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\n",
    "- Convolutional Layer 5\n",
    "    GPU1 - (256 filters, 3 x 3, stride 1, padding 1) -> (output dim: (256, 15, 15))\n",
    "    GPU2 - (256 filters, 3 x 3, stride 1, padding 1) -> (output dim: (256, 15, 15))\n",
    "- Max Pooling Layer 3\n",
    "    GPU1 - (3 x 3, stride 2) -> (output dim: (256, 7, 7))\n",
    "    GPU2 - (3 x 3, stride 2) -> (output dim: (256, 7, 7))\n",
    "- Fully Connected Layer 1\n",
    "    GPU1 - (4096 neurons) -> (output dim: (4096))\n",
    "    GPU2 - (4096 neurons) -> (output dim: (4096))\n",
    "- Fully Connected Layer 2\n",
    "    GPU1 - (4096 neurons) -> (output dim: (4096))\n",
    "    GPU2 - (4096 neurons) -> (output dim: (4096))\n",
    "- Fully Connected Layer 3\n",
    "    1000 Neurons -> (output dim: (1000))\n",
    "- Softmax Layer\n",
    "    1000 Neurons -> (output dim: (1000))\n",
    "    \n",
    "Instead of using 2 GPUs, we will make the network branching.\n",
    "\n",
    "Keep in mind this:\n",
    "\n",
    "```\n",
    "Now we are ready to describe the overall architecture of our CNN. As depicted in Figure 2, the net\n",
    "contains eight layers with weights; the first five are convolutional and the remaining three are fullyconnected. The output of the last fully-connected layer is fed to a 1000-way softmax which produces\n",
    "a distribution over the 1000 class labels. Our network maximizes the multinomial logistic regression\n",
    "objective, which is equivalent to maximizing the average across training cases of the log-probability\n",
    "of the correct label under the prediction distribution.\n",
    "The kernels of the second, fourth, and fifth convolutional layers are connected only to those kernel\n",
    "maps in the previous layer which reside on the same GPU (see Figure 2). The kernels of the third\n",
    "convolutional layer are connected to all kernel maps in the second layer. The neurons in the fullyconnected layers are connected to all neurons in the previous layer. Response-normalization layers\n",
    "follow the first and second convolutional layers. Max-pooling layers, of the kind described in Section\n",
    "3.4, follow both response-normalization layers as well as the fifth convolutional layer. The ReLU\n",
    "non-linearity is applied to the output of every convolutional and fully-connected layer\n",
    "```\n",
    "\n",
    "Training Parameters / Hyperparamters:\n",
    "- Data Augmentation: Randomly cropped 224x224 patches from the 256x256 images, and horizontally mirroring them.\n",
    "    - This means that on test time, the image is resized to 256x256, and then 5 224x224 patches are cropped from it, and mirrored, and the network is run on all of them. The final prediction is the average of the 10 predictions.\n",
    "- They wrote a Cuda ConvNet from scratch to train the network. BASED\n",
    "- SGD with momentum 0.9 and weight decay 0.0005\n",
    "- Batch Size: 128\n",
    "\n",
    "Metrics Defined:\n",
    "Error Rate\n",
    "- Number of misclassified test samples / Total number of test samples\n",
    "\n",
    "Top 1 vs top 5 error rate\n",
    "- Top 1 error rate is the number of test samples for which the correct label is not among the top 1 predicted labels\n",
    "- Top 5 error rate is the number of test samples for which the correct label is not among the top 5 predicted labels\n",
    "\n",
    "Results:\n",
    "- Top-1 error rate: 37.5%\n",
    "- Top-5 error rate: 17.0%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "Architecture:\n",
    "Input (3 x 256, 256)\n",
    "- Convolutional Layer 1 \n",
    "    GPU1 - (96 filters, 11 x 11, stride 4, padding 0) -> (output dim: (96, 62, 62))\n",
    "    GPU2 - (96 filters, 11 x 11, stride 4, padding 0) -> (output dim: (96, 62, 62))\n",
    "- Max Pooling Layer 1\n",
    "    GPU1 - (3 x 3, stride 2) -> (output dim: (96, 31, 31))\n",
    "    GPU2 - (3 x 3, stride 2) -> (output dim: (96, 31, 31))\n",
    "- Convolutional Layer 2\n",
    "    GPU1 - (256 filters, 5 x 5, stride 1, padding 2) -> (output dim: (256, 31, 31))\n",
    "    GPU2 - (256 filters, 5 x 5, stride 1, padding 2) -> (output dim: (256, 31, 31))\n",
    "- Max Pooling Layer 2\n",
    "    GPU1 - (3 x 3, stride 2) -> (output dim: (256, 15, 15))\n",
    "    GPU2 - (3 x 3, stride 2) -> (output dim: (256, 15, 15))\n",
    "- Convolutional Layer 3\n",
    "    GPU1 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\n",
    "    GPU2 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\n",
    "- Convolutional Layer 4\n",
    "    GPU1 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\n",
    "    GPU2 - (384 filters, 3 x 3, stride 1, padding 1) -> (output dim: (384, 15, 15))\n",
    "- Convolutional Layer 5\n",
    "    GPU1 - (256 filters, 3 x 3, stride 1, padding 1) -> (output dim: (256, 15, 15))\n",
    "    GPU2 - (256 filters, 3 x 3, stride 1, padding 1) -> (output dim: (256, 15, 15))\n",
    "- Max Pooling Layer 3\n",
    "    GPU1 - (3 x 3, stride 2) -> (output dim: (256, 7, 7))\n",
    "    GPU2 - (3 x 3, stride 2) -> (output dim: (256, 7, 7))\n",
    "- Fully Connected Layer 1\n",
    "    GPU1 - (4096 neurons) -> (output dim: (4096))\n",
    "    GPU2 - (4096 neurons) -> (output dim: (4096))\n",
    "- Fully Connected Layer 2\n",
    "    GPU1 - (4096 neurons) -> (output dim: (4096))\n",
    "    GPU2 - (4096 neurons) -> (output dim: (4096))\n",
    "- Fully Connected Layer 3\n",
    "    1000 Neurons -> (output dim: (1000))\n",
    "- Softmax Layer\n",
    "    1000 Neurons -> (output dim: (1000))\n",
    "    \n",
    "Instead of using 2 GPUs, we will make the network branching.\n",
    "\n",
    "Keep in mind this:\n",
    "\n",
    "```\n",
    "Now we are ready to describe the overall architecture of our CNN. As depicted in Figure 2, the net\n",
    "contains eight layers with weights; the first five are convolutional and the remaining three are fullyconnected. The output of the last fully-connected layer is fed to a 1000-way softmax which produces\n",
    "a distribution over the 1000 class labels. Our network maximizes the multinomial logistic regression\n",
    "objective, which is equivalent to maximizing the average across training cases of the log-probability\n",
    "of the correct label under the prediction distribution.\n",
    "The kernels of the second, fourth, and fifth convolutional layers are connected only to those kernel\n",
    "maps in the previous layer which reside on the same GPU (see Figure 2). The kernels of the third\n",
    "convolutional layer are connected to all kernel maps in the second layer. The neurons in the fullyconnected layers are connected to all neurons in the previous layer. Response-normalization layers\n",
    "follow the first and second convolutional layers. Max-pooling layers, of the kind described in Section\n",
    "3.4, follow both response-normalization layers as well as the fifth convolutional layer. The ReLU\n",
    "non-linearity is applied to the output of every convolutional and fully-connected layer\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# Since the Sub Sampling as mentioned by Yunn LeCun is not the same as Average Pooling, I will implement it as a trainable layer\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=(3, 11, 11), stride=(1, 4, 4), padding=0)\n",
    "        self.conv2 = nn.Conv2d(96, 256, kernel_size=(96, 5, 5), stride=(1, 1, 1), padding=2)\n",
    "        self.conv3 = nn.Conv2d(256, 384, kernel_size=(256, 3, 3), stride=(1, 1, 1), padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 384, kernel_size=(384, 3, 3), stride=(1, 1, 1), padding=1)\n",
    "        self.conv5 = nn.Conv2d(384, 256, kernel_size=(384, 3, 3), stride=(1, 1, 1), padding=1)\n",
    "        self.fc1 = nn.Linear(256*7*7, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        x = x.view(-1, 256*7*7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet().cuda()\n",
    "image = torch.randn(1, 3, 256, 256)\n",
    "output = model(image.cuda()).cpu()\n",
    "print(output.size()) # torch.Size([1, 1000]) as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./data && mkdir -p ./data/Imagenet\n",
    "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz -O ./data/Imagenet/ILSVRC2012_devkit_t12.tar.gz\n",
    "# !tar -xvf ./data/Imagenet/ILSVRC2012_devkit_t12.tar.gz\n",
    "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tar -O ./data/Imagenet/ILSVRC2012_img_train.tar\n",
    "# !tar -xvf ./data/Imagenet/ILSVRC2012_img_train.tar\n",
    "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar -O ./data/Imagenet/ILSVRC2012_img_val.tar\n",
    "# !tar -xvf ./data/Imagenet/ILSVRC2012_img_val.tar\n",
    "\n",
    "# Run the following in a tmuxs session on the server for background download\n",
    "#mkdir -p ./data && mkdir -p ./data/Imagenet && wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz -O ./data/Imagenet/ILSVRC2012_devkit_t12.tar.gz && tar -xvf ./data/Imagenet/ILSVRC2012_devkit_t12.tar.gz && wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tar -O ./data/Imagenet/ILSVRC2012_img_train.tar && tar -xvf ./data/Imagenet/ILSVRC2012_img_train.tar && wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar -O ./data/Imagenet/ILSVRC2012_img_val.tar && tar -xvf ./data/Imagenet/ILSVRC2012_img_val.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageNet\n",
    "\n",
    "train_data = ImageNet(root='./data/Imagenet', split='train')\n",
    "val_data = ImageNet(root='./data/Imagenet', split='val')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
